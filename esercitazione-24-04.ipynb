{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"487d6a0e","cell_type":"markdown","source":"# **Esercitazione 4 - Classificatori: KNN e Decision Trees**\n\nIn questa esercitazione applicheremo quanto appreso sui classificatori. Nello specifico utilizzeremo:\n\n* **K-Nearest Neighbors (KNN):** Un algoritmo di classificazione basato sulla similarità che assegna una classe a un'osservazione in base alle classi dei suoi \"K\" vicini più prossimi.\n\n* **Decision Trees:** Un modello di classificazione che utilizza una struttura ad albero per prendere decisioni basate su regole derivate dalle caratteristiche dei dati.","metadata":{}},{"id":"1c0e7c81","cell_type":"markdown","source":"### **Dataset Breast Cancer**\n\nIl dataset di riferimento sarà `breast_cancer`, un noto dataset di classificazione che contiene informazioni su tumori al seno. Le osservazioni includono diverse caratteristiche misurate sui tumori, come dimensioni, forma e altre metriche, con l'obiettivo di classificare i tumori in due categorie: **benigni** e **maligni**.\n\nPer questa esercitazione, utilizzeremo l'intero dataset, mantenendo le classi originali. Il dataset è composto da 569 campioni e 30 caratteristiche, e utilizzeremo questo set per costruire i modelli di classificazione.\n\nIl codice seguente esegue l'importazione delle librerie necessarie, il caricamento del dataset `breast_cancer` e la preparazione dei dati. In particolare, gestiremo i dati e le etichette in modo da facilitare l'uso dei classificatori K-Nearest Neighbors (KNN) e Decision Trees.\n\nDal caricamente del dataset estrarremo anche i nomi delle feature e della variabile target perchè ci servirà più avanti.","metadata":{}},{"id":"08d3ff15","cell_type":"code","source":"# Importazione delle librerie necessarie\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import load_breast_cancer\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:40:46.809831Z","iopub.execute_input":"2025-04-27T17:40:46.810154Z","iopub.status.idle":"2025-04-27T17:40:48.252339Z","shell.execute_reply.started":"2025-04-27T17:40:46.810126Z","shell.execute_reply":"2025-04-27T17:40:48.251532Z"}},"outputs":[],"execution_count":1},{"id":"8f8b8f61","cell_type":"code","source":"# Caricamento del dataset Iris\ndataset = load_breast_cancer()\nX = dataset.data\ny = dataset.target\n\n# Estraggo nomi delle feature e dei target\nfeature_names = dataset.feature_names\ntarget_names = dataset.target_names","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.689Z"}},"outputs":[],"execution_count":null},{"id":"724f22cb","cell_type":"markdown","source":"### **Divisione e standardizzazione del dataset** \n\nDividiamo il dataset in `train set`, `validation set` e `test set` utilizzando le proporzioni già impostate. Successivamente applichiamo la standardizzazione utilizzando `StandardScaler`.","metadata":{}},{"id":"84b8b157","cell_type":"code","source":"# Usare le seguenti proporzioni per il train, validation e test\ntrain_fraction = 0.6  \nvalidation_fraction = 0.2  \ntest_fraction = 0.2\n\ntrain_dim= int(X.shape[0]*train_fraction)\nval_dim= int(X.shape[0]*validation_fraction)\nX_train=X[:train_dim]\nY_train=y[:train_dim]\nX_validation=X[train_dim:train_dim+val_dim]\nY_validation=y[train_dim:train_dim+val_dim]\n\nX_test=X[train_dim+val_dim:]\nY_test=y[train_dim+val_dim:]\n\n\nscaler = StandardScaler()\n\nX_train=scaler.fit_transform(X_train)\nX_validation=scaler.transform(X_validation)\nX_test=scaler.transform(X_test)\n\n\n\nprint(\"train shape: \", X_train.shape)\nprint(\"test shape: \", X_validation.shape)\nprint(\"valadation shape: \", X_test.shape)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.690Z"}},"outputs":[],"execution_count":null},{"id":"5102c517","cell_type":"markdown","source":"## **Esercizio 1: Implementare K-NN**\n\nPer implementare il classificatore K-Nearest Neighbors utilizzeremo la classe `sklearn.neighbors.KNeighborsClassifier` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html).\n\nDi seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell'istanza:\n\n* **`n_neighbors`**: Numero di vicini da considerare. Valori più elevati implicano una maggiore generalizzazione.\n* **`weights`**: Specifica come pesare i vicini; può essere `uniform` (tutti i vicini hanno lo stesso peso) o `distance` (i vicini più prossimi hanno un peso maggiore).\n* **`metric`**: Tipo di distanza da utilizzare per calcolare la distanza tra i punti (ad esempio, `euclidean`, `manhattan`, ecc.).\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n# Importo KNeighborsClassifier da scikit-learn\nfrom sklearn.neighbors import KNeighborsClassifier\n\n# 1. Instanzio il modello KNN\n# Durante la creazione dell'istanza imposto i parametri che desidero\nmodel = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n\n# 2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n# 3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)\n\n```","metadata":{}},{"id":"90f5938f","cell_type":"markdown","source":"### **Guida per la risoluzione del K-Nearest Neighbors (KNN)**\n\nDi seguito sono spiegati i passaggi principali per la risoluzione dell'esercizio utilizzando il classificatore K-Nearest Neighbors.\n\n1. **Creazione del modello:** Creare un'istanza della classe `KNeighborsClassifier`, specificando i parametri presentati poco sopra. In particolare vogliamo i seguenti parametri:\n\n    - `n_neighbors` = 5\n\n    - `weights` = `'uniform'` (o `'distance'` se vuoi dare un peso maggiore ai vicini più prossimi)\n\n    - `metric` = `'euclidean'` (puoi cambiare con `'manhattan'` se preferisci un'altra metrica di distanza)\n\n2. **Addestramento del modello:** Addestriamo il modello utilizzando il metodo `.fit()`. Il modello deve essere addestrato sui dati di training. Assicurati che i dati siano adeguatamente preprocessati e, se necessario, normalizzati o standardizzati.\n\n3. **Calcolo delle predizioni:** Calcoliamo le predizioni sul validation e sul test set utilizzando il metodo `.predict()` del modello.\n\n4. **Valutazione delle prestazioni del modello:** Calcoliamo l'accuracy del modello. Possono essere utilizzate anche altre metriche, come la precisione, il richiamo e il punteggio F1, per ottenere una valutazione più completa. Dobbiamo valutare il modello sia sul validation set che sul test set e infine stampare il valore di accuracy su entrambi i set.\n\n5. **Calcolare la matrice di confusione:** Calcolare la matrice di confusione.","metadata":{}},{"id":"6803b23b","cell_type":"code","source":"# Step 1: Creazione del modello KNN\nfrom sklearn.neighbors import KNeighborsClassifier\n\nmodel = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.690Z"}},"outputs":[],"execution_count":null},{"id":"66ea01d4","cell_type":"code","source":"# Step 2: Addestramento del modello KNN\n\nmodel.fit(X_train, Y_train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.691Z"}},"outputs":[],"execution_count":null},{"id":"d396900e","cell_type":"code","source":"# Step 3: Calcolo delle predizioni\n\ny_predictions_test = model.predict(X_test)\ny_predictions_validation = model.predict(X_validation)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.691Z"}},"outputs":[],"execution_count":null},{"id":"d40ef061","cell_type":"code","source":"# Step 4: Valutazione del modello KNN\ni = 0\ncount = 0\nfor label in y_predictions_validation:\n    if label == Y_validation[i]:\n        count = count+1\n    i = i+1\naccuracy_validation = count/len(y_predictions_validation)\nprint(\"Accuracy validation: \", accuracy_validation)\n\ni = 0\ncount = 0\nfor label in y_predictions_test:\n    if label == Y_test[i]:\n        count = count+1\n    i = i+1\naccuracy_test = count/len(y_predictions_test)\nprint(\"Accuracy test: \", accuracy_test)\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.692Z"}},"outputs":[],"execution_count":null},{"id":"3142e27e","cell_type":"markdown","source":"#### Funzione alternativa per il calcolo dell' accuracy\n\nFinora abbiamo calcolato manualmente il valore dell' accuracy. Ovvero abbiamo confrontato il vettore delle predizioni con il vettore dei target e successivamente contato quanti campioni combaciano, in modo da avere il numero di predizioni effettuate correttamente. Possiamo effettuare questo calcolo anche utilizzando una funzione di `sklearn`.\n\nLa funzione `accuracy_score` infatti ci calcola in automatico il valore dell' accuracy. La sintassi per utilizarla è la seguente\n\n```python\n# Importo accuracy_score da scikit-learn\nfrom sklearn.metrics import accuracy_score\n\naccuracy = accuracy_score(y_true, y_pred)\n\n```","metadata":{}},{"id":"354dc544","cell_type":"code","source":"# Step 4.1: Calcolare l' accuracy con accuracy_score\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy_test = accuracy_score(Y_test, y_predictions_test)\naccuracy_validaton = accuracy_score(Y_validation, y_predictions_validation)\nprint(\"Accuracy test: \", accuracy_test)\nprint(\"Accuracy validation: \", accuracy_validation)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.692Z"}},"outputs":[],"execution_count":null},{"id":"9cc51143","cell_type":"code","source":"# Step 5: Calcolare la matrice di confusione\n\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncm = confusion_matrix(Y_test, y_predictions_test)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.693Z"}},"outputs":[],"execution_count":null},{"id":"c83cdbd2","cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\n\ndef plot_decision_boundary(knn_model, X_train, y_train):\n\n    h = 0.1  \n    x_min, x_max = X_train[:, 0].min() - 1, X_train[:, 0].max() + 1\n    y_min, y_max = X_train[:, 1].min() - 1, X_train[:, 1].max() + 1\n    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n    \n    Z = knn_model.predict(np.c_[xx.ravel(), yy.ravel()])\n    Z = Z.reshape(xx.shape)\n\n    unique_classes = np.unique(y_train)\n    \n    plt.figure(figsize=(10, 8))\n    plt.contourf(xx, yy, Z, alpha=0.5, cmap=plt.cm.RdYlBu)  \n    \n    scatter = plt.scatter(X_train[:, 0], X_train[:, 1], c=y_train, edgecolors='k', marker='o', \n                          label='Training set', cmap=plt.cm.RdYlBu, s=20)  \n\n    plt.title(f'Confini Decisionali di K-Nearest Neighbors')\n    plt.legend(scatter.legend_elements()[0], unique_classes, title='Classi')\n    plt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.693Z"}},"outputs":[],"execution_count":null},{"id":"c4ef4dfc","cell_type":"markdown","source":"### Visualizzazione K-NN\n\nPer visualizzare il margine di classificazione del nostro K-NN dobbiamo utilizzare soltanto 2 features. Poichè nel dataset ne sono presenti 30 abbiamo due soluzioni:\n\n1. **Utilizzare le prime due features del dataset:** soluzione più rapida ma che non ci garantisce un risultato ottimale, in quanto l' ordine delle features non ha alcuna rilevanza circa la loro importanza. **ATTENZIONE:** poichè stiamo utilizzando solo 2 features, dobbiamo riaddestrare il K-NN sul dataset ridotto.\n\n2. **Applicare PCA con 2 componenti:** applichiamo la PCA con due componenti che utilizziamo successivamente per trasformare i nostri dati.\n\nDi seguito applicheremo entrambe le soluzioni e alla fine confronteremo i risultati.","metadata":{}},{"id":"8829d633","cell_type":"code","source":"X_train_2f = X_train[:, :2]\nX_validation_2f = X_validation[:, :2]\nX_test_2f = X_test[:, :2]\n\n# Standardizzazione\nscaler = StandardScaler()\nX_train_2f = scaler.fit_transform(X_train_2f)\nX_validation_2f = scaler.transform(X_validation_2f)\nX_test_2f = scaler.transform(X_test_2f)\n\n# Creiamo e addestriamo il K-NN\nmodel2 = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\nmodel2.fit(X_train_2f, Y_train)\n\n# Predizioni\ny_predictions_test = model2.predict(X_test_2f)\ny_predictions_validation = model2.predict(X_validation_2f)\n\n# Confusion matrix\ncm = confusion_matrix(Y_test, y_predictions_test)\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\nplt.title(\"Confusion Matrix (Test Set)\")\nplt.xlabel(\"Predicted\")\nplt.ylabel(\"Actual\")\nplt.show()\n\n\n# Visualizziamo il confine decisionale\nplot_decision_boundary(model2, X_train_2f, Y_train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.694Z"}},"outputs":[],"execution_count":null},{"id":"a641f56a","cell_type":"code","source":"# Visualizzazione con PCA\n\n\nfrom sklearn.decomposition import PCA\n\nscaler = StandardScaler()\nX_train2 = scaler.fit_transform(X_train)\nX_validation2 = scaler.transform(X_validation)\n\n# Applichiamo PCA per ridurre il dataset a 2 dimensioni. ATTENZIONE: per applicare PCA dobbiamo prima standardizzare.\npca = PCA(n_components=2) \nX_train2 = pca.fit_transform(X_train2) \nX_validation2 = pca.transform(X_validation2)\n\nprint(X_train2.shape)\nprint(X_validation2.shape)\n\n\n# Classificatore KNN su dati PCA\nmodel2 = KNeighborsClassifier(n_neighbors=5, weights='uniform', metric='euclidean')\nmodel2.fit(X_train2, Y_train)\ny_predictions_validation = model2.predict(X_validation2)\ncm = confusion_matrix(Y_validation, y_predictions_validation)\n\n# Plot\nplot_decision_boundary(model2, X_train2, Y_train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.694Z"}},"outputs":[],"execution_count":null},{"id":"f4c49b73","cell_type":"markdown","source":"## **Esercizio 2: valutare le prestazioni di K-NN al variare di k e metrica**\n\nValutiamo come variano le prestazioni del classificatore al variare di:\n\n* **k:** usiamo diversi valori di k.\n\n* **metrica**: usiamo diverse distanze, non solo quella euclidea.\n\n\n### **Guida:**\n\n1. **Testiamo il classificatore al variare del parametro:** che sia il k o la distanza, dobbiamo istanziare, allenare e valutare il classificatore per ogni valore che ci interessa. Alla fine di ogni test che effettuiamo, saliamo il valore di accuracy ottenuto in una lista.\n\n2. **Valutazione grafica:** utilizziamo la funzione di plot per valutare quale valore del parametro di interesse ci fa ottenere la performance migliore.\n\n","metadata":{}},{"id":"c5068b74","cell_type":"code","source":"# Funzione per la valutazione grafica\n\ndef plot_accuracy_k(k_values, train_scores, test_scores):\n    plt.figure(figsize=(12, 6))\n    \n    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n    \n    plt.xlabel('Numero di k')\n    plt.ylabel('Accuratezza')\n    plt.title('KNN: Accuratezza vs. Valore di k')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.695Z"}},"outputs":[],"execution_count":null},{"id":"57f7baf2","cell_type":"code","source":"# Valutiamo le performance al variare di k\n\nk_values = range(1, 15) \ntrain_scores = []\ntest_scores = []\n\n# Istanziamo, alleniamo e valutiamo un K-NN per ogni valore di k \nfor k in k_values:\n    model = KNeighborsClassifier(n_neighbors=k, weights='uniform', metric='euclidean')\n    model.fit(X_train, Y_train)\n    y_predictions_traink = model.predict(X_train)\n    y_predictions_testk = model.predict(X_test)\n    \n    accuracy_test_k = accuracy_score(Y_test, y_predictions_testk)\n    accuracy_train_k = accuracy_score(Y_train, y_predictions_traink)\n    #print(accuracy_test_k)\n    \n\n    train_scores.append(accuracy_train_k)\n    test_scores.append(accuracy_test_k)\n\n\nplot_accuracy_k(k_values,train_scores,test_scores)\n   \n\n# Visualizziamo le performance al variare di k\n# N.B. la funzione plot_accuracy_k ha bisogno dei parametri k_values, train_scores, test_scores.\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.695Z"}},"outputs":[],"execution_count":null},{"id":"2a66262d","cell_type":"code","source":"# Funzione per plottare l' accuracy al variare delle metriche\n\ndef plot_accuracy_metric(metrics, train_scores, test_scores):\n    bar_width = 0.35\n    x = np.arange(len(metrics))  \n\n    plt.figure(figsize=(12, 6))\n\n    color_train = plt.cm.RdYlBu(0.9)  \n    color_test = plt.cm.RdYlBu(0.4)   \n\n    bars_train = plt.bar(x - bar_width/2, train_scores.values(), width=bar_width, label='Training', color=color_train)\n    bars_test = plt.bar(x + bar_width/2, test_scores.values(), width=bar_width, label='Testing', color=color_test)\n\n    plt.xticks(ticks=x, labels=metrics)  \n    plt.xlabel('Metriche')\n    plt.ylabel('Accuratezza')\n    plt.title('KNN: Accuratezza vs. Metriche')\n    plt.legend(loc='lower right')\n    plt.grid(axis='y')\n    \n    for bar in bars_train:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n\n    for bar in bars_test:\n        yval = bar.get_height()\n        plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 2), ha='center', va='bottom')\n\n    plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.696Z"}},"outputs":[],"execution_count":null},{"id":"7021496a","cell_type":"code","source":"# Valutiamo le performance al variare della metrica\n# in questo caso le performance devono essere salvate in un dizionario. Ogni chiave sarà il nome della metrica usata, il valore corrispondente invece sarà l' accuracy ottenuta.\n\nmetrics = ['euclidean', 'manhattan', 'minkowski', 'cosine']\ntest_scores = {}\ntrain_scores = {}\n\n# Istanziamo, alleniamo e valutiamo un K-NN per ogni metrica. Utilizziamo k=5.\nfor metric in metrics:\n    model = KNeighborsClassifier(n_neighbors=7, weights='uniform', metric=metric)\n    model.fit(X_train, Y_train)\n    y_predictions_train_m = model.predict(X_train)\n    y_predictions_test_m = model.predict(X_test)\n    \n    accuracy_test_m = accuracy_score(Y_test, y_predictions_test_m)\n    accuracy_train_m = accuracy_score(Y_train, y_predictions_train_m)\n    \n\n    train_scores[metric] = accuracy_train_m\n    test_scores[metric] = accuracy_test_m\n\n\n# Visualizziamo le performance al variare della metrica\n# N.B. la funzione plot_accuracy_metric ha bisogno dei parametri metrics, train_scores, test_scores.\nplot_accuracy_metric(metrics, train_scores, test_scores)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.696Z"}},"outputs":[],"execution_count":null},{"id":"432f7f94","cell_type":"markdown","source":"## **Esercizio 2: Implementare Decision Trees**\n\nPer implementare il classificatore Decision Tree, utilizzeremo la classe `sklearn.tree.DecisionTreeClassifier` presente in `scikit-learn`. La documentazione è disponibile [a questo link](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html).\n\nDi seguito vediamo i parametri chiave che bisogna specificare al momento della creazione dell'istanza:\n\n* **`criterion`**: Funzione da utilizzare per misurare la qualità di uno split. \n\n* **`max_depth`**: Profondità massima dell'albero. Limitare la profondità aiuta a prevenire l'overfitting.\n\n* **`min_samples_split`**: Numero minimo di campioni richiesti per dividere un nodo. Valori più alti rendono l'albero più conservativo.\n\n* **`min_samples_leaf`**: Numero minimo di campioni che devono essere presenti in un nodo foglia. Prevenire nodi foglia con pochi campioni può migliorare la generalizzazione.\n\n\n### Esempio di sintassi per istanziare, addestrare e predire\n\n```python\n# Importo DecisionTreeClassifier da scikit-learn\nfrom sklearn.tree import DecisionTreeClassifier\n\n# 1. Instanzio il modello Decision Tree\n# Durante la creazione dell'istanza imposto i parametri che desidero\nmodel = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=10)\n\n# 2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, y_train)\n\n# 3. Calcolo delle predizioni utilizzando il metodo .predict()\npredictions = model.predict(X_test)\n","metadata":{}},{"id":"afcba9f7","cell_type":"markdown","source":"## **Esercizio 3: Istanziare allenare e valutare un modello DecisionTree**\n\nIn linea con quanto visto finora, istanziamo, alleniamo e valutiamo un modello di DecisionTree. Utilizziamo:\n\n* `criterion`=`'entropy'`\n\n* `random_state` = 42 \n\nIl valore di `random_state` non ha un significato particolare, ma ci permette di rendere l' esperimento deterministico. \n\nI passaggi per questo esercizio sono uguali a quanto visto in precedenza per K-NN.","metadata":{}},{"id":"29449cdc","cell_type":"code","source":"# Importiamo DecisionTree \nfrom sklearn.tree import DecisionTreeClassifier, plot_tree","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.697Z"}},"outputs":[],"execution_count":null},{"id":"54090eec","cell_type":"code","source":"# Step 1 - Creiamo un albero decisionale\n\n# 1. Instanzio il modello Decision Tree\n# Durante la creazione dell'istanza imposto i parametri che desidero\nmodel = DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=10)\n\n\n# Step 2 - Alleniamo il modello\n# 2. Train del modello utilizzando il metodo .fit()\nmodel.fit(X_train, Y_train)\n\n\n# Step 3 - Calcoliamo le predizioni\n\npredictions_validation = model.predict(X_validation)\npredictions_test = model.predict(X_test)\n\n\n# Step 4 - Valutiamo il modello, calcoliamo accuracy e confusion matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\naccuracy_test2 = accuracy_score(Y_test, predictions_test)\naccuracy_validation2 = accuracy_score(Y_validation, predictions_validation)\n\nprint(\"Accuracy test: \", accuracy_test2)\nprint(\"Accuracy validation: \", accuracy_validation2)\n\n\n\ncm = confusion_matrix(Y_test, predictions_test)\n\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.697Z"}},"outputs":[],"execution_count":null},{"id":"e7a16dfe","cell_type":"code","source":"# Visualizzazione dell'albero creato\n# dovete sostituire alla funzione plot_tree il primo parametro. Nello specifico dovete sostituirlo con il nome che avete dato al vostro DecisionTree.\n\nplt.figure(figsize=(20, 10))\nplot_tree(model, feature_names=feature_names, class_names=target_names, \n          filled=True, rounded=True, fontsize=12)\nplt.title('Decision Tree')\nplt.show()\n","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.697Z"}},"outputs":[],"execution_count":null},{"id":"4ff6d7f0","cell_type":"markdown","source":"## **Esercizio 4: Valutiamo le performance di un DecisionTree al variare di alcuni parametri**\n\nCome abbiamo fatto per K-NN, vogliamo valutare come variano le performance di un Decision Tree al variare di alcuni parametri. Nello specifico vogliamo valutare il modello al variare di:\n\n* **`max_depth`**: Profondità massima dell'albero. \n","metadata":{}},{"id":"689aea93","cell_type":"code","source":"# Funzione per plottare l' accuracy al variare della max_depth del modello\n\ndef plot_accuracy_depth(k_values, train_scores, test_scores):\n    plt.figure(figsize=(12, 6))\n    \n    plt.plot(k_values, train_scores, 'o-', label='Accuratezza Training')\n    plt.plot(k_values, test_scores, 'o-', label='Accuratezza Testing')\n    \n    plt.xlabel('Profondità massima dell\\'albero')\n    plt.ylabel('Accuratezza')\n    plt.title('Decision Tree: Accuratezza vs. Depth')\n    plt.legend()\n    plt.grid(True)\n    plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.698Z"}},"outputs":[],"execution_count":null},{"id":"7f9d03e7","cell_type":"code","source":"# Confrontiamo alberi con diverse profondità massime\n\nmax_depths = [2, 3, 4, 5]\ntrain_accuracy = []\ntest_accuracy = []\n\n# Istanziamo, alleniamo e valutiamo un DecisionTree per ogni valore di max_depth\nfor max_depth in max_depths:\n    model_p = DecisionTreeClassifier(criterion='entropy', max_depth=max_depth, min_samples_split=10)\n    model_p.fit(X_train, Y_train)\n    predictions_train_p = model_p.predict(X_train)\n    predictions_test_p = model_p.predict(X_test)\n\n    accuracy_test_p = accuracy_score(Y_test, predictions_test_p)\n    accuracy_train_p = accuracy_score(Y_train, predictions_train_p)\n\n    train_accuracy.append(accuracy_train_p)\n    test_accuracy.append(accuracy_test_p)\n    \n\n\n# Visualizziamo l'effetto della profondità sull'accuratezza\n\nplot_accuracy_depth(max_depths, train_accuracy, test_accuracy)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.698Z"}},"outputs":[],"execution_count":null},{"id":"58b02676","cell_type":"markdown","source":"## **Esercizio 5: Ottimizzazione Decision Tree con GridSearch e Cross Validation**\n\nPossiamo ottimizzare le performance di un Decision Tree specificando ulteriori parametri. Lo scopo di questo esercizio è trovare la miglior combinazione di parametri che massimizza l' accuracy del nostro modello. Per trovare questa configurazione utilizzeremo la funzione `GridSearchCV` che effettua Grid Search e Cross Validation contemporaneamente.\n\nInnanzitutto proviamo a istanziare un Decision Tree specificando più parametri. Nello specifico impostiamo:\n\n* `max_depth` = `3`\n\n* `min_samples_split` = `5`\n\n* `min_samples_leaf` = `2`\n\nVediamo se l' aggiunta di questi parametri incrementa le performance ottenute precedentemente.\n\nOvviamente i parametri impostati precedentemente devono essere mantenuti.","metadata":{}},{"id":"12b14dc2","cell_type":"code","source":"# Albero ottimizzato con parametri più controllati\n\n# Istanziamo il nuovo albero specificando tutti i parametri di cui abbiamo bisogno.\n\nmodel_3 = DecisionTreeClassifier(criterion='entropy', max_depth=3, min_samples_split=5, min_samples_leaf=2)\nmodel_3.fit(X_train, Y_train)\npredictions_validation_3 = model_3.predict(X_validation)\npredictions_test_3 = model_3.predict(X_test)\n\naccuracy_test_3 = accuracy_score(Y_test, predictions_test_3)\naccuracy_validation_3 = accuracy_score(Y_validation, predictions_validation_3)\n\n\n\n\n# Rappresentiamo il nuovo albero\n# Dovete sostituire il primo parametro della funzione plot_tree con il nome del vostro albero.\n\nplt.figure(figsize=(15, 8))\nplot_tree(model_3, feature_names=feature_names, class_names=target_names, \n          filled=True, rounded=True, fontsize=10)\nplt.title('Albero Decisionale')\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.698Z"}},"outputs":[],"execution_count":null},{"id":"65dda958","cell_type":"markdown","source":"#### **Importanza delle features**\n\nPossiamo estrarre dal nostro modello Decision Tree l' importanza delle singole feature, cioè quanto una feature aiuda a ridurre il criterio scelto, l' entropia nel nostro caso. \n\nQuesta informazione è contenuta in `.feature_importances_`. \n\nUna volta estratti questi valori, ordiniamoli in ordine decrescente e utilizziamo la funzione `plot_top_feature_importance` definita nella cella seguente per rappresentarne il grafico. La funzione richiede due parametri:\n\n* **Vettore importanze:** il vettore contenente l' importanza delle features ottenuto dall' estrazione.\n\n* **Nomi delle features:** i nomi delle feature che abbiamo estratto all' inizio dell' esercitazione quando abbiamo importato il dataset.","metadata":{}},{"id":"e43f274b","cell_type":"code","source":"def plot_top_feature_importance(importances, feature_names):\n    # Ordina le importanze e ottieni i primi `top_n` indici\n    top_n=10\n    indices = np.argsort(importances)[::-1][:top_n]\n\n    plt.figure(figsize=(10, 6))\n    plt.title('Importanza delle Feature')\n    \n    # Plotta solo le prime `top_n` barre\n    plt.bar(range(top_n), importances[indices], align='center', color='skyblue')\n    \n    plt.xticks(range(top_n), [feature_names[i] for i in indices], rotation=45)\n    plt.xlabel('Feature')\n    plt.ylabel('Importanza')\n    plt.tight_layout()  # Aggiunge spazio tra i lati del grafico\n    plt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.699Z"}},"outputs":[],"execution_count":null},{"id":"30b07808","cell_type":"code","source":"# Estrai l' importanza delle features da .feature_importances_\n\nimportances=model_3.feature_importances_\n\n# Riordina in ordine decrescente\ni=np.argsort(importances)[::-1]\nimportances=importances[i]\n\n# Rappresentiamo il grafico\nplot_top_feature_importance(importances, feature_names)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.699Z"}},"outputs":[],"execution_count":null},{"id":"b437e3d1","cell_type":"markdown","source":"### **Grid search**\n\nPoichè i parametri impostabili in un modello sono numerosi testare le singole configurazioni è dispendioso. Tuttavia la ricerca dei parametri ottimali è l' unico modo che abbiamo per assicurarci di estrarre la miglior performance dal nostro modello. In questi casi ci sono diverse strateggie per cercare la configurazione migliore. Una di questa è la **Grid search** (letteralmente **ricerca a griglia**) che consiste nel testare tutte le possibili configurazioni e selezionare la migliore. Chiaramente testare tutte le configurazioni rende il grid search un algoritmo molto dispendioso dal punto di vista computazionale.\n\nPossiamo implementare un algoritmo di grid search utilizzando la classe `GridSearchCV` di `sklearn` che effettua contemporaneamente ricerca a griglia e cross-validation. \n\n#### Guida per Grid Search:\n\nI seguenti passaggi devono guidarvi all' utilizzo di `GridSearchCV` per trovare la miglior configurazione per un modello di DecisionTree per il nostro dataset.\n\n1. **Istanziamo un' oggetto `GridSearchCV`:** per creare l' oggetto `GridSearchCV` dobbiamo specificare i seguenti parametri\n\n    * Modello che vogliamo usare\n\n    * Dizionario contenente come chiavi i parametri che vogliamo testare, e come value i valori che vogliamo impiegare\n\n    * `cv` cioè il nomero di fold che vogliamo utilizzare per la cross-validaton\n\n    * `scoring` ovvero la metrica da utilizzare per valutare, ad esempio `accuracy`\n\n2. **Eseguire Grid Search:** utilizziamo il metodo `.fit()` dell' oggetto `GridSearchCV` definito al punto 1 per eseguire l' algoritmo\n\n3. **Stampare configurazione migliore:** dopo aver eseguito il `.fit()`, l' oggetto `GridSearchCV` ci permette di accedere ad alcuni attributi:\n\n    * `.best_params_`: un dizionario che rappresenta la miglior configurazione.\n\n    * `.best_scores_`: il valore migliore ottenuto come accuracy.\n\n    * `.best_estimator_`: il modello allenato con la configurazione migliore. ","metadata":{}},{"id":"851f3973","cell_type":"code","source":"# Step 1 - Istanziare l' oggetto GridSearchCV\n\nfrom sklearn.model_selection import GridSearchCV\n\n# Definizione del grid di parametri\nparam_grid = {\n    'max_depth': [3, 4, 5, 6, 7, None],\n    'min_samples_split': [2, 5, 10],\n    'min_samples_leaf': [1, 2, 4],\n    'criterion': ['entropy']\n}\n\nG=GridSearchCV(model_3, param_grid, cv=4, scoring ='accuracy') ","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.699Z"}},"outputs":[],"execution_count":null},{"id":"91b20d57","cell_type":"code","source":"# Step 2 - Eseguire Grid Search\n\nG.fit(X_train, Y_train)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.700Z"}},"outputs":[],"execution_count":null},{"id":"bd109bd5","cell_type":"code","source":"# Step 3 - Stampare i risultati\n# Stampare la migliore configurazione e la migliore accuracy\n\nprint(G.best_params_)\nprint(G.best_score_)\nprint(G.best_estimator_)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-04-27T17:25:50.700Z"}},"outputs":[],"execution_count":null},{"id":"18b8e613","cell_type":"markdown","source":"# **Esercizio 6: Model Selection classificatori**\n\nAvendo affrontato tutti i classificatori visti in questo corso, possiamo adesso procedere alla fase di **model selection**. Vogliamo trovare quale classificatore la relativa configurazione che meglio performano su uno specifico dataset. \n\n### **Dataset**\n\nPer questo esercizio utilizzeremo il dataset `Vehicle Silhouette` che trovato al seguente [link](https://archive.ics.uci.edu/dataset/149/statlog+vehicle+silhouettes). Il dataset contiene 846 campioni su 18 features, e contiene informazioni circa le dimensioni di alcuni veicoli. L' obiettivo è classificare ogni campione in 4 possibili classi. ","metadata":{}},{"id":"bab558cf","cell_type":"code","source":"!pip install ucimlrepo","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:41:03.416976Z","iopub.execute_input":"2025-04-27T17:41:03.417420Z","iopub.status.idle":"2025-04-27T17:41:08.447005Z","shell.execute_reply.started":"2025-04-27T17:41:03.417396Z","shell.execute_reply":"2025-04-27T17:41:08.445784Z"}},"outputs":[{"name":"stdout","text":"Collecting ucimlrepo\n  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\nRequirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2.2.3)\nRequirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.11/dist-packages (from ucimlrepo) (2025.1.31)\nRequirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (1.26.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2.4.1)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.23.2->pandas>=1.0.0->ucimlrepo) (2024.2.0)\nDownloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\nInstalling collected packages: ucimlrepo\nSuccessfully installed ucimlrepo-0.0.7\n","output_type":"stream"}],"execution_count":2},{"id":"8ffb9b39","cell_type":"code","source":"from ucimlrepo import fetch_ucirepo \n  \n# fetch dataset \nstatlog_vehicle_silhouettes = fetch_ucirepo(id=149) \n  \n# data (as pandas dataframes) \nX = statlog_vehicle_silhouettes.data.features \ny = statlog_vehicle_silhouettes.data.targets \ny_flat = np.ravel(y)\n\ny_series = pd.Series(y_flat)\n\nprint(\"Distribuzione delle classi (prima):\")\nprint(y_series.value_counts())\n\nclassi_da_mantenere = y_series.value_counts()[y_series.value_counts() > 1].index\nprint(\"\\nClassi da mantenere (con >1 campione):\", list(classi_da_mantenere))\n\nmask = y_series.isin(classi_da_mantenere)\n\nX = X[mask]\ny = y_series[mask]\n\nprint(\"\\nDistribuzione delle classi dopo il filtraggio:\")\nprint(y.value_counts())\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:41:11.331913Z","iopub.execute_input":"2025-04-27T17:41:11.332804Z","iopub.status.idle":"2025-04-27T17:41:12.730943Z","shell.execute_reply.started":"2025-04-27T17:41:11.332767Z","shell.execute_reply":"2025-04-27T17:41:12.729953Z"}},"outputs":[{"name":"stdout","text":"Distribuzione delle classi (prima):\nsaab    217\nbus     217\nopel    212\nvan     199\n204       1\nName: count, dtype: int64\n\nClassi da mantenere (con >1 campione): ['saab', 'bus', 'opel', 'van']\n\nDistribuzione delle classi dopo il filtraggio:\nsaab    217\nbus     217\nopel    212\nvan     199\nName: count, dtype: int64\n","output_type":"stream"}],"execution_count":3},{"id":"10713cae","cell_type":"code","source":"# fai quattro modelli di classificatori; alleno ogni modello e colcolo l'accuracy; cercare l'accuracy migliore\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\n\ntrain_fraction = 0.6  \nvalidation_fraction = 0.2  \ntest_fraction = 0.2\n\ntrain_dim= int(X.shape[0]*train_fraction)\nval_dim= int(X.shape[0]*validation_fraction)\nX_train=X[:train_dim]\nY_train=y[:train_dim]\nX_validation=X[train_dim:train_dim+val_dim]\nY_validation=y[train_dim:train_dim+val_dim]\n\nX_test=X[train_dim+val_dim:]\nY_test=y[train_dim+val_dim:]\n\n\nscaler = StandardScaler()\n\nX_train2=scaler.fit_transform(X_train)\nX_validation2=scaler.transform(X_validation)\nX_test2=scaler.transform(X_test)\n\n\n\nprint(\"train shape: \", X_train2.shape)\nprint(\"test shape: \", X_validation2.shape)\nprint(\"valadation shape: \", X_test2.shape)\n\nmodels = {\n    \"Logistic Regression\": LogisticRegression(),\n    \"Decision Tree\": DecisionTreeClassifier(criterion='entropy', max_depth=5, min_samples_split=10),\n    \"K-Nearest Neighbors\": KNeighborsClassifier(n_neighbors=7, weights='uniform', metric='euclidean'),\n    \"Support Vector Machine\": SVC( kernel ='linear', C=1) \n}\n\n\nres_val = {}\n\nfor nome, model in models.items():\n    model.fit(X_train2, Y_train)\n    y_val_pred = model.predict(X_validation2)\n    acc_val = accuracy_score(Y_validation, y_val_pred)\n    res_val[nome] = acc_val\n    print(f\"{nome}: Accuracy sul Validation Set = {acc_val:.4f}\")\n\n\nbest_model_nome = max(res_val, key=res_val.get)\nbest_model = models[best_model_nome]\n\n\nprint(f\"\\n Miglior modello (validation): {best_model_nome} con accuracy {res_val[best_model_nome]:.4f}\")\n\n\ny_test_pred = best_model.predict(X_test2)\nfinal_acc = accuracy_score(Y_test, y_test_pred)\nprint(f\"\\n Accuracy finale sul Test Set = {final_acc:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-27T17:41:16.387200Z","iopub.execute_input":"2025-04-27T17:41:16.388100Z","iopub.status.idle":"2025-04-27T17:41:16.642733Z","shell.execute_reply.started":"2025-04-27T17:41:16.388065Z","shell.execute_reply":"2025-04-27T17:41:16.641888Z"}},"outputs":[{"name":"stdout","text":"train shape:  (507, 18)\ntest shape:  (169, 18)\nvaladation shape:  (169, 18)\nLogistic Regression: Accuracy sul Validation Set = 0.7515\nDecision Tree: Accuracy sul Validation Set = 0.6568\nK-Nearest Neighbors: Accuracy sul Validation Set = 0.6568\nSupport Vector Machine: Accuracy sul Validation Set = 0.7574\nricerca miglior modello\n\n Miglior modello (validation): Support Vector Machine con accuracy 0.7574\n\n Accuracy finale sul Test Set = 0.8639\n","output_type":"stream"}],"execution_count":4}]}